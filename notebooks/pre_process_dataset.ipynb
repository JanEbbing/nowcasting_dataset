{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ed2241-5fae-4982-b27c-7e16ac3c986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nowcasting_dataset.datamodule import NowcastingDataModule\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import numcodecs\n",
    "import gcsfs\n",
    "from typing import List\n",
    "\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger('nowcasting_dataset')\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f088d0-32c2-4578-b264-07cf44e22d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = Path('solar-pv-nowcasting-data')\n",
    "\n",
    "# Solar PV data\n",
    "PV_PATH = BUCKET / 'PV/PVOutput.org'\n",
    "PV_DATA_FILENAME = PV_PATH / 'UK_PV_timeseries_batch.nc'\n",
    "PV_METADATA_FILENAME = PV_PATH / 'UK_PV_metadata.csv'\n",
    "\n",
    "# SAT_FILENAME = BUCKET / 'satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr_int16_single_timestep_quarter_geospatial.zarr'\n",
    "SAT_FILENAME = BUCKET / 'satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr_int16_single_timestep.zarr'\n",
    "\n",
    "# Numerical weather predictions\n",
    "#NWP_BASE_PATH = BUCKET / 'NWP/UK_Met_Office/UKV_zarr'\n",
    "#NWP_BASE_PATH = BUCKET / 'NWP/UK_Met_Office/UKV_single_step_and_single_timestep_all_vars.zarr'\n",
    "#NWP_BASE_PATH = BUCKET / 'NWP/UK_Met_Office/UKV_single_step_and_single_timestep_all_vars_full_spatial_2018_7-12_float32.zarr'\n",
    "NWP_BASE_PATH = BUCKET / 'NWP/UK_Met_Office/UKV__2018-01_to_2019-12__chunks__variable10__init_time1__step1__x548__y704__.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe4d6e4-e9c3-4f42-a47f-53bdc903eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'gs://solar-pv-nowcasting-data/prepared_ML_training_data/testing.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9359c9b-1ecd-41d4-9613-a4fbe61cbfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    batch_size=32,\n",
    "    history_len=6,  #: Number of timesteps of history, not including t0.\n",
    "    forecast_len=12,  #: Number of timesteps of forecast.\n",
    "    image_size_pixels=32,\n",
    "    nwp_channels=('t', 'dswrf', 'prate', 'r', 'sde', 'si10', 'vis', 'lcc', 'mcc', 'hcc'),\n",
    "    sat_channels=(\n",
    "        'HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120',\n",
    "        'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87204c81-40d5-4c5a-84c0-fe757e61b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = NowcastingDataModule(\n",
    "    pv_power_filename=PV_DATA_FILENAME,\n",
    "    pv_metadata_filename=f'gs://{PV_METADATA_FILENAME}',\n",
    "    sat_filename = f'gs://{SAT_FILENAME}',\n",
    "    nwp_base_path = f'gs://{NWP_BASE_PATH}',\n",
    "    pin_memory = True,  #: Passed to DataLoader.\n",
    "    num_workers = 16,  #: Passed to DataLoader.\n",
    "    prefetch_factor = 8,  #: Passed to DataLoader.\n",
    "    n_samples_per_timestep = 8,  #: Passed to NowcastingDataset\n",
    "    n_training_batches_per_epoch = 50_000,\n",
    "    collate_fn = lambda x: x,\n",
    "    convert_to_numpy = False,  #: Leave data as Pandas / Xarray for pre-preparing.\n",
    "    **params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb2f98b-aa30-4bf9-9b35-2046b1ef3847",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2aed91-9f70-4a56-b226-41586fbc8f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff96d7f3-9ba9-4c26-8c0b-623a13688b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.train_t0_datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ddf1d7-3702-41d1-aa82-8d6ca5a5de1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.val_t0_datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dff704e-69b4-435e-969c-e37b3b07a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader():\n",
    "    train_dl = data_module.train_dataloader()\n",
    "    return train_dl\n",
    "\n",
    "train_dl = get_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f4328-d37c-4040-a503-bb03b602c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import numcodecs\n",
    "from concurrent import futures\n",
    "import zarr\n",
    "import gcsfs\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a7aeb8-01db-4c9d-a355-f5847c724190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_to_arange(da: xr.DataArray, dim: str, prefix: str, dtype=np.int32) -> xr.DataArray:\n",
    "    coord = da[dim]\n",
    "    da[dim] = np.arange(len(coord), dtype=dtype)\n",
    "    da[f'{prefix}_{dim}_coords'] = xr.DataArray(coord, coords=[da[dim]], dims=[dim])\n",
    "    return da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e846c36-7c87-48ff-b0f8-07be3de7e129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def concat_examples(examples, start_example_index=0):\n",
    "    datasets = []\n",
    "    for i, example in enumerate(examples):\n",
    "        individual_datasets = []\n",
    "        example_dim = {'example': np.array([i+start_example_index], dtype=np.int32)}\n",
    "        for name in ['sat_data', 'nwp']:\n",
    "            ds = example[name].to_dataset(name=name)\n",
    "            short_name = name.replace('_data', '')\n",
    "            if name == 'nwp':\n",
    "                ds = ds.rename({'target_time': 'time'})\n",
    "            for dim in ['time', 'x', 'y']:\n",
    "                ds = coord_to_arange(ds, dim, prefix=short_name)\n",
    "            ds = ds.rename({\n",
    "                'variable': f'{short_name}_variable', \n",
    "                'x': f'{short_name}_x', \n",
    "                'y': f'{short_name}_y',\n",
    "            })\n",
    "            individual_datasets.append(ds)\n",
    "\n",
    "        # PV\n",
    "        pv_yield = example['pv_yield'].rename('pv_yield').to_xarray().rename({'datetime': 'time'}).to_dataset()\n",
    "        pv_yield = coord_to_arange(pv_yield, 'time', prefix='pv_yield')\n",
    "        # This will expand all dataarrays to have an 'example' dim.\n",
    "        for name in ['pv_system_id', 'pv_system_row_number']:\n",
    "            pv_yield[name] = xr.DataArray([example[name]], coords=example_dim, dims=['example'])\n",
    "        individual_datasets.append(pv_yield)\n",
    "\n",
    "        # Merge\n",
    "        merged_ds = xr.merge(individual_datasets)\n",
    "        datasets.append(merged_ds)\n",
    "    return xr.concat(datasets, dim='example')\n",
    "\n",
    "\n",
    "def fix_dtypes(concat_ds):\n",
    "    ds_dtypes = {\n",
    "        'example': np.int32, 'sat_x_coords': np.int32, 'sat_y_coords': np.int32, \n",
    "        'nwp': np.float32, 'nwp_x_coords': np.float32, 'nwp_y_coords': np.float32,\n",
    "        'pv_system_id': np.int32, 'pv_system_row_number': np.int32}\n",
    "\n",
    "    for name, dtype in ds_dtypes.items():\n",
    "        concat_ds[name] = concat_ds[name].astype(dtype)\n",
    "    return concat_ds\n",
    "\n",
    "\n",
    "def write_examples(examples, start_example_index=0):\n",
    "    concat_ds = concat_examples(examples, start_example_index=start_example_index)\n",
    "    concat_ds = fix_dtypes(concat_ds)\n",
    "    target_chunks = {'example': 32}\n",
    "    concat_ds = concat_ds.chunk(target_chunks)\n",
    "    encoding = {\n",
    "        name: {'compressor': numcodecs.Blosc(cname=\"zstd\", clevel=5)}\n",
    "        for name in concat_ds.data_vars}\n",
    "\n",
    "    gcs = gcsfs.GCSFileSystem()\n",
    "    if gcs.exists(filename):\n",
    "        to_zarr_kwargs = dict(append_dim='example')\n",
    "    else:\n",
    "        to_zarr_kwargs = dict(encoding=encoding, mode='w')\n",
    "\n",
    "    zarr_store = concat_ds.to_zarr(filename, **to_zarr_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0eeba6-760f-4c0f-b7a7-3bd7aa603413",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "examples = []\n",
    "start_example_index = 0\n",
    "print('Getting first batch')\n",
    "for batch_i, batch in enumerate(train_dl):\n",
    "    print(f'Got batch {batch_i}')\n",
    "    examples.extend(batch)\n",
    "    if batch_i % 32 == 0:\n",
    "        print('Writing!')\n",
    "        write_examples(examples, start_example_index=start_example_index)\n",
    "        start_example_index += len(examples)\n",
    "        examples = []\n",
    "    print('getting next batch...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32613c9b-3a0a-4a7a-bb62-79a9f33614bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nowcasting_dataset",
   "language": "python",
   "name": "nowcasting_dataset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
