{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ed2241-5fae-4982-b27c-7e16ac3c986b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jack/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/pytorch_lightning/metrics/__init__.py:43: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  rank_zero_deprecation(\n"
     ]
    }
   ],
   "source": [
    "from nowcasting_dataset.datamodule import NowcastingDataModule\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb0430bf-7df9-4da5-ba27-14b9e385aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15f088d0-32c2-4578-b264-07cf44e22d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = Path('solar-pv-nowcasting-data')\n",
    "\n",
    "# Solar PV data\n",
    "PV_PATH = BUCKET / 'PV/PVOutput.org'\n",
    "PV_DATA_FILENAME = PV_PATH / 'UK_PV_timeseries_batch.nc'\n",
    "PV_METADATA_FILENAME = PV_PATH / 'UK_PV_metadata.csv'\n",
    "\n",
    "SAT_FILENAME = BUCKET / 'satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr_int16_single_timestep_quarter_geospatial.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87204c81-40d5-4c5a-84c0-fe757e61b43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46 µs, sys: 7 µs, total: 53 µs\n",
      "Wall time: 55.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_module = NowcastingDataModule(\n",
    "    pv_power_filename=PV_DATA_FILENAME,\n",
    "    pv_metadata_filename=f'gs://{PV_METADATA_FILENAME}',\n",
    "    batch_size = 32,\n",
    "    history_len = 0,  #: Number of timesteps of history, not including t0.\n",
    "    forecast_len = 1,  #: Number of timesteps of forecast.\n",
    "    sat_filename = f'gs://{SAT_FILENAME}',\n",
    "    pin_memory = True,  #: Passed to DataLoader.\n",
    "    num_workers = 16,  #: Passed to DataLoader.\n",
    "    prefetch_factor = 256,  #: Passed to DataLoader.\n",
    "    n_samples_per_timestep = 2,  #: Passed to NowcastingDataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e16ce731-0d4a-4684-87b1-e07d786e12da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.29 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#data_module.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a1e5556-a223-480b-ae12-84069d3ebe19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 3.81 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b5a6369-0f60-4256-af54-6d449da8271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_module.train_t0_datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd09cc49-7ab5-45ba-90fc-12ea54635aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_module.val_t0_datetimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cee088-d110-4e7f-a917-2ab3acaa5eff",
   "metadata": {},
   "source": [
    "## Define very simple ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2984ce1d-1655-41b2-b6d9-5d439e26806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_images_in_model(images, device):    \n",
    "    SAT_IMAGE_MEAN = torch.tensor(93.23458, dtype=torch.float, device=device)\n",
    "    SAT_IMAGE_STD = torch.tensor(115.34247, dtype=torch.float, device=device)\n",
    "    \n",
    "    images = images.float()\n",
    "    images -= SAT_IMAGE_MEAN\n",
    "    images /= SAT_IMAGE_STD\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26cfd2b8-8d2e-4823-b558-cc7c900f1a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS = 32\n",
    "KERNEL = 3\n",
    "\n",
    "\n",
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        history_len: int=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.history_len = history_len\n",
    "        \n",
    "        self.encoder_conv1 = nn.Conv2d(in_channels=1, out_channels=CHANNELS//2, kernel_size=KERNEL)\n",
    "        self.encoder_conv2 = nn.Conv2d(in_channels=CHANNELS//2, out_channels=CHANNELS, kernel_size=KERNEL)\n",
    "        self.encoder_conv3 = nn.Conv2d(in_channels=CHANNELS, out_channels=CHANNELS, kernel_size=KERNEL)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=KERNEL)\n",
    "        \n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=CHANNELS * 11 * 11, \n",
    "            out_features=256  # Minus 2 (2 for the NWP temperature above the PV system)\n",
    "        )\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=128)\n",
    "        self.fc4 = nn.Linear(in_features=128, out_features=128)\n",
    "        self.fc5 = nn.Linear(in_features=128, out_features=1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        images = x['sat_data'][:, self.history_len:, :, :, 0]\n",
    "        images = normalise_images_in_model(images, self.device)\n",
    "        \n",
    "        # Pass data through the network :)\n",
    "        out = F.relu(self.encoder_conv1(images))\n",
    "        out = self.maxpool(out)\n",
    "        out = F.relu(self.encoder_conv2(out))\n",
    "        out = self.maxpool(out)\n",
    "        out = F.relu(self.encoder_conv3(out))\n",
    "        \n",
    "        out = out.view(-1, CHANNELS * 11 * 11)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        \n",
    "        out = torch.cat(\n",
    "            (\n",
    "                out, \n",
    "                #(x['nwp_above_pv'][:, 0] - 130) / 5,  # TODO fix horrible standardisation of temperature!\n",
    "            ), dim=1)\n",
    "\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = F.relu(self.fc3(out))\n",
    "        out = F.relu(self.fc4(out))\n",
    "        out = self.fc5(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def _training_or_validation_step(self, batch, is_train_step):\n",
    "        y_hat = self(batch)\n",
    "        y = batch['pv_yield'][:, self.history_len:]\n",
    "        #y = torch.rand((32, 1), device=self.device)\n",
    "        #mse_loss = F.mse_loss(y_hat, y)\n",
    "        mae_loss = (y_hat - y).abs().mean()\n",
    "        tag = \"Train\" if is_train_step else \"Validation\"\n",
    "        #self.log_dict({'MSE/' + tag: mse_loss}, on_step=is_train_step, on_epoch=True)\n",
    "        self.log_dict({'MAE/' + tag: mae_loss}, on_step=is_train_step, on_epoch=True)\n",
    "        return mae_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._training_or_validation_step(batch, is_train_step=True)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._training_or_validation_step(batch, is_train_step=False)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eee05878-ad3e-46a9-9719-37eab1505997",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitAutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d53ba3d3-e9a9-4948-829f-b6b2a6199d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eb05006-b2df-426c-a775-e41402abf7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 bad systems found.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "<class 'dask.dataframe.core.Index'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7b6b8391c42e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    456\u001b[0m         )\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_setup_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# allow user to setup lightning_module in accelerator environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_configure_sharded_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# allow user to setup in model sharded environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# note: this sets up self.lightning_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mcall_setup_hook\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/ocf/nowcasting_dataset/nowcasting_dataset/datamodule.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_has_prepared_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mall_datetimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_datetimes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         t0_datetimes = nd_time.get_t0_datetimes(\n\u001b[1;32m    120\u001b[0m             \u001b[0mdatetimes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_datetimes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_seq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_seq_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/ocf/nowcasting_dataset/nowcasting_dataset/datamodule.py\u001b[0m in \u001b[0;36m_get_datetimes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mdata_source\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             for data_source in self.data_sources]\n\u001b[0;32m--> 177\u001b[0;31m         datetimes = nd_time.intersection_of_datetimeindexes(\n\u001b[0m\u001b[1;32m    178\u001b[0m             all_datetime_indexes)\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mall_datetime_indexes\u001b[0m  \u001b[0;31m# save memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/ocf/nowcasting_dataset/nowcasting_dataset/time.py\u001b[0m in \u001b[0;36mintersection_of_datetimeindexes\u001b[0;34m(indexes)\u001b[0m\n\u001b[1;32m     48\u001b[0m         indexes: List[pd.DatetimeIndex]) -> pd.DatetimeIndex:\n\u001b[1;32m     49\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mintersection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/ocf/nowcasting_dataset/nowcasting_dataset/time.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m         indexes: List[pd.DatetimeIndex]) -> pd.DatetimeIndex:\n\u001b[1;32m     49\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mintersection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/pandas/core/indexes/datetimes.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, freq, tz, normalize, closed, ambiguous, dayfirst, yearfirst, dtype, copy, name)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_extract_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         dtarr = DatetimeArray._from_sequence_not_strict(\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36m_from_sequence_not_strict\u001b[0;34m(cls, data, dtype, copy, tz, freq, dayfirst, yearfirst, ambiguous)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq_infer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_infer_freq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         subarr, tz, inferred_freq = sequence_to_dt64ns(\n\u001b[0m\u001b[1;32m    327\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36msequence_to_dt64ns\u001b[0;34m(data, dtype, copy, tz, dayfirst, yearfirst, ambiguous)\u001b[0m\n\u001b[1;32m   2021\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2023\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"M8[ns]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: <class 'dask.dataframe.core.Index'>"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nowcasting_dataset",
   "language": "python",
   "name": "nowcasting_dataset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
