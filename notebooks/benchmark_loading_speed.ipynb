{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ed2241-5fae-4982-b27c-7e16ac3c986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nowcasting_dataset.datamodule import NowcastingDataModule\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb0430bf-7df9-4da5-ba27-14b9e385aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15f088d0-32c2-4578-b264-07cf44e22d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = Path('solar-pv-nowcasting-data')\n",
    "\n",
    "# Solar PV data\n",
    "PV_PATH = BUCKET / 'PV/PVOutput.org'\n",
    "PV_DATA_FILENAME = PV_PATH / 'UK_PV_timeseries_batch.nc'\n",
    "PV_METADATA_FILENAME = PV_PATH / 'UK_PV_metadata.csv'\n",
    "\n",
    "SAT_FILENAME = BUCKET / 'satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr_int16_single_timestep_quarter_geospatial.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87204c81-40d5-4c5a-84c0-fe757e61b43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52 µs, sys: 9 µs, total: 61 µs\n",
      "Wall time: 63.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_module = NowcastingDataModule(\n",
    "    pv_power_filename=PV_DATA_FILENAME,\n",
    "    pv_metadata_filename=f'gs://{PV_METADATA_FILENAME}',\n",
    "    batch_size = 32,\n",
    "    history_len = 0,  #: Number of timesteps of history, not including t0.\n",
    "    forecast_len = 1,  #: Number of timesteps of forecast.\n",
    "    sat_filename = f'gs://{SAT_FILENAME}',\n",
    "    sat_channels = None, #('HRV', 'WV_062', 'WV_073'),\n",
    "    pin_memory = True,  #: Passed to DataLoader.\n",
    "    num_workers = 8,  #: Passed to DataLoader.\n",
    "    prefetch_factor = 256,  #: Passed to DataLoader.\n",
    "    n_samples_per_timestep = 2,  #: Passed to NowcastingDataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cee088-d110-4e7f-a917-2ab3acaa5eff",
   "metadata": {},
   "source": [
    "## Define very simple ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2984ce1d-1655-41b2-b6d9-5d439e26806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_images_in_model(images, device):\n",
    "    SAT_IMAGE_MEAN = torch.tensor(\n",
    "        [\n",
    "            93.23458, 131.71373, 843.7779 , 736.6148 , 771.1189 , 589.66034,\n",
    "            862.29816, 927.69586,  90.70885, 107.58985, 618.4583 , 532.47394\n",
    "        ],\n",
    "        dtype=torch.float, device=device)\n",
    "    SAT_IMAGE_STD = torch.tensor(\n",
    "        [\n",
    "            115.34247 , 139.92636 ,  36.99538 ,  57.366386,  30.346825,\n",
    "            149.68007 ,  51.70631 ,  35.872967, 115.77212 , 120.997154,\n",
    "            98.57828 ,  99.76469\n",
    "        ],\n",
    "        dtype=torch.float, device=device)\n",
    "    \n",
    "    images = images.float()\n",
    "    images = images - SAT_IMAGE_MEAN.unsqueeze(-1).unsqueeze(-1)\n",
    "    images = images / SAT_IMAGE_STD.unsqueeze(-1).unsqueeze(-1)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26cfd2b8-8d2e-4823-b558-cc7c900f1a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS = 144\n",
    "KERNEL = 3\n",
    "\n",
    "\n",
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        history_len: int=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.history_len = history_len\n",
    "        \n",
    "        self.encoder_conv1 = nn.Conv2d(in_channels=12, out_channels=CHANNELS//2, kernel_size=KERNEL, groups=12)\n",
    "        self.encoder_conv2 = nn.Conv2d(in_channels=CHANNELS//2, out_channels=CHANNELS, kernel_size=KERNEL, groups=CHANNELS//2)\n",
    "        self.encoder_conv3 = nn.Conv2d(in_channels=CHANNELS, out_channels=CHANNELS, kernel_size=KERNEL, groups=CHANNELS)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=KERNEL)\n",
    "        \n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=CHANNELS * 11 * 11, \n",
    "            out_features=256  # Minus 2 (2 for the NWP temperature above the PV system)\n",
    "        )\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=128)\n",
    "        self.fc4 = nn.Linear(in_features=128, out_features=128)\n",
    "        self.fc5 = nn.Linear(in_features=128, out_features=1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        images = x['sat_data'][:, self.history_len, :, :, :]\n",
    "        images = images.permute(0, 3, 2, 1)  # Conv2d expects channels to be the 2nd dim!\n",
    "        images = normalise_images_in_model(images, self.device)\n",
    "        \n",
    "        # Pass data through the network :)\n",
    "        out = F.relu(self.encoder_conv1(images))\n",
    "        out = self.maxpool(out)\n",
    "        out = F.relu(self.encoder_conv2(out))\n",
    "        out = self.maxpool(out)\n",
    "        out = F.relu(self.encoder_conv3(out))\n",
    "        \n",
    "        out = out.view(-1, CHANNELS * 11 * 11)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        \n",
    "        out = torch.cat(\n",
    "            (\n",
    "                out, \n",
    "                #(x['nwp_above_pv'][:, 0] - 130) / 5,  # TODO fix horrible standardisation of temperature!\n",
    "            ), dim=1)\n",
    "\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = F.relu(self.fc3(out))\n",
    "        out = F.relu(self.fc4(out))\n",
    "        out = self.fc5(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def _training_or_validation_step(self, batch, is_train_step):\n",
    "        y_hat = self(batch)\n",
    "        y = batch['pv_yield'][:, self.history_len:]\n",
    "        #y = torch.rand((32, 1), device=self.device)\n",
    "        #mse_loss = F.mse_loss(y_hat, y)\n",
    "        mae_loss = (y_hat - y).abs().mean()\n",
    "        tag = \"Train\" if is_train_step else \"Validation\"\n",
    "        #self.log_dict({'MSE/' + tag: mse_loss}, on_step=is_train_step, on_epoch=True)\n",
    "        self.log_dict({'MAE/' + tag: mae_loss}, on_step=is_train_step, on_epoch=True)\n",
    "        return mae_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._training_or_validation_step(batch, is_train_step=True)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._training_or_validation_step(batch, is_train_step=False)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee05878-ad3e-46a9-9719-37eab1505997",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitAutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d53ba3d3-e9a9-4948-829f-b6b2a6199d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb05006-b2df-426c-a775-e41402abf7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 bad PV systems found and removed!\n",
      "pv_power = 400.0 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type      | Params\n",
      "--------------------------------------------\n",
      "0 | encoder_conv1 | Conv2d    | 720   \n",
      "1 | encoder_conv2 | Conv2d    | 1.4 K \n",
      "2 | encoder_conv3 | Conv2d    | 1.4 K \n",
      "3 | maxpool       | MaxPool2d | 0     \n",
      "4 | fc1           | Linear    | 4.5 M \n",
      "5 | fc2           | Linear    | 32.9 K\n",
      "6 | fc3           | Linear    | 16.5 K\n",
      "7 | fc4           | Linear    | 16.5 K\n",
      "8 | fc5           | Linear    | 129   \n",
      "--------------------------------------------\n",
      "4.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.5 M     Total params\n",
      "18.122    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|                                                                  | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jack/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 0it [00:00, ?it/s]                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 124it [00:38,  3.24it/s, loss=0.129, v_num=126]"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c4c66f-cdc5-4319-b7c8-0b7dddf438d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nowcasting_dataset",
   "language": "python",
   "name": "nowcasting_dataset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
