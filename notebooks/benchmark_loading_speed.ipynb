{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ed2241-5fae-4982-b27c-7e16ac3c986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nowcasting_dataset.datamodule import NowcastingDataModule\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger('nowcasting_dataset')\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f088d0-32c2-4578-b264-07cf44e22d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = Path('solar-pv-nowcasting-data')\n",
    "\n",
    "# Solar PV data\n",
    "PV_PATH = BUCKET / 'PV/PVOutput.org'\n",
    "PV_DATA_FILENAME = PV_PATH / 'UK_PV_timeseries_batch.nc'\n",
    "PV_METADATA_FILENAME = PV_PATH / 'UK_PV_metadata.csv'\n",
    "\n",
    "# SAT_FILENAME = BUCKET / 'satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr_int16_single_timestep_quarter_geospatial.zarr'\n",
    "SAT_FILENAME = BUCKET / 'satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr_int16_single_timestep.zarr'\n",
    "\n",
    "# Numerical weather predictions\n",
    "NWP_BASE_PATH = BUCKET / 'NWP/UK_Met_Office/UKV_zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87204c81-40d5-4c5a-84c0-fe757e61b43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 107 µs, sys: 0 ns, total: 107 µs\n",
      "Wall time: 111 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_module = NowcastingDataModule(\n",
    "    pv_power_filename=PV_DATA_FILENAME,\n",
    "    pv_metadata_filename=f'gs://{PV_METADATA_FILENAME}',\n",
    "    batch_size = 32,\n",
    "    history_len = 0,  #: Number of timesteps of history, not including t0.\n",
    "    forecast_len = 1,  #: Number of timesteps of forecast.\n",
    "    sat_filename = f'gs://{SAT_FILENAME}',\n",
    "    # sat_channels =('HRV', 'WV_062', 'WV_073'),\n",
    "    nwp_base_path = f'gs://{NWP_BASE_PATH}',\n",
    "    pin_memory = True,  #: Passed to DataLoader.\n",
    "    num_workers = 1,  #: Passed to DataLoader.\n",
    "    prefetch_factor = 256,  #: Passed to DataLoader.\n",
    "    n_samples_per_timestep = 8,  #: Passed to NowcastingDataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feb2f98b-aa30-4bf9-9b35-2046b1ef3847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:nowcasting_dataset:Opening satellite data: gs://solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr_int16_single_timestep.zarr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 bad PV systems found and removed!\n",
      "pv_power = 400.0 MB\n",
      "CPU times: user 56.9 s, sys: 3.63 s, total: 1min\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_module.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd2aed91-9f70-4a56-b226-41586fbc8f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:nowcasting_dataset:Opening satellite data: gs://solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr_int16_single_timestep.zarr\n",
      "DEBUG:nowcasting_dataset:Opening NWP data: gs://solar-pv-nowcasting-data/NWP/UK_Met_Office/UKV_zarr\n",
      "DEBUG:nowcasting_dataset:Opening satellite data: gs://solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr_int16_single_timestep.zarr\n",
      "/home/jack/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/pvlib/solarposition.py:368: FutureWarning: casting datetime64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
      "  unixtime = np.array(time.astype(np.int64)/10**9)\n",
      "/home/jack/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/pvlib/solarposition.py:368: FutureWarning: casting datetime64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
      "  unixtime = np.array(time.astype(np.int64)/10**9)\n",
      "/home/jack/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/pvlib/solarposition.py:368: FutureWarning: casting datetime64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
      "  unixtime = np.array(time.astype(np.int64)/10**9)\n",
      "/home/jack/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/pvlib/solarposition.py:368: FutureWarning: casting datetime64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
      "  unixtime = np.array(time.astype(np.int64)/10**9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.7 s, sys: 349 ms, total: 14 s\n",
      "Wall time: 18.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jack/dev/ocf/nowcasting_dataset/nowcasting_dataset/utils.py:20: FutureWarning: casting datetime64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
      "  a = a.astype(int)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cee088-d110-4e7f-a917-2ab3acaa5eff",
   "metadata": {},
   "source": [
    "## Define very simple ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2984ce1d-1655-41b2-b6d9-5d439e26806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_images_in_model(images, device):\n",
    "    SAT_IMAGE_MEAN = torch.tensor(\n",
    "        [\n",
    "            93.23458, 131.71373, 843.7779 , 736.6148 , 771.1189 , 589.66034,\n",
    "            862.29816, 927.69586,  90.70885, 107.58985, 618.4583 , 532.47394\n",
    "        ],\n",
    "        dtype=torch.float, device=device)\n",
    "    SAT_IMAGE_STD = torch.tensor(\n",
    "        [\n",
    "            115.34247 , 139.92636 ,  36.99538 ,  57.366386,  30.346825,\n",
    "            149.68007 ,  51.70631 ,  35.872967, 115.77212 , 120.997154,\n",
    "            98.57828 ,  99.76469\n",
    "        ],\n",
    "        dtype=torch.float, device=device)\n",
    "    \n",
    "    images = images.float()\n",
    "    images = images - SAT_IMAGE_MEAN.unsqueeze(-1).unsqueeze(-1)\n",
    "    images = images / SAT_IMAGE_STD.unsqueeze(-1).unsqueeze(-1)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26cfd2b8-8d2e-4823-b558-cc7c900f1a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS = 144\n",
    "KERNEL = 3\n",
    "EMBEDDING_DIM = 0\n",
    "NWP_SIZE = 10 * 2 * 2  # channels x width x height\n",
    "\n",
    "\n",
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        history_len: int=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.history_len = history_len\n",
    "        \n",
    "        self.sat_conv1 = nn.Conv2d(in_channels=12, out_channels=CHANNELS//2, kernel_size=KERNEL, groups=12)\n",
    "        self.sat_conv2 = nn.Conv2d(in_channels=CHANNELS//2, out_channels=CHANNELS, kernel_size=KERNEL, groups=CHANNELS//2)\n",
    "        self.sat_conv3 = nn.Conv2d(in_channels=CHANNELS, out_channels=CHANNELS, kernel_size=KERNEL, groups=CHANNELS)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=KERNEL)\n",
    "        \n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=CHANNELS * 11 * 11, \n",
    "            out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=256 + EMBEDDING_DIM + NWP_SIZE, out_features=128)\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=128)\n",
    "        self.fc4 = nn.Linear(in_features=128, out_features=128)\n",
    "        self.fc5 = nn.Linear(in_features=128, out_features=1)\n",
    "        \n",
    "        if EMBEDDING_DIM:\n",
    "            self.pv_system_id_embedding = nn.Embedding(\n",
    "                num_embeddings=len(data_module.pv_data_source.pv_metadata),\n",
    "                embedding_dim=EMBEDDING_DIM\n",
    "            )\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        sat_data = x['sat_data'][:, self.history_len]\n",
    "        sat_data = sat_data.permute(0, 3, 2, 1)  # Conv2d expects channels to be the 2nd dim!\n",
    "        sat_data = normalise_images_in_model(sat_data, self.device)\n",
    "        \n",
    "        # Pass data through the network :)\n",
    "        out = F.relu(self.sat_conv1(sat_data))\n",
    "        out = self.maxpool(out)\n",
    "        out = F.relu(self.sat_conv2(out))\n",
    "        out = self.maxpool(out)\n",
    "        out = F.relu(self.sat_conv3(out))\n",
    "        \n",
    "        out = out.view(-1, CHANNELS * 11 * 11)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        \n",
    "        nwp_data = x['nwp'][:, :, self.history_len] # Shape: batch_size, channel, seq_length, width, height\n",
    "        batch_size, n_nwp_chans, nwp_width, nwp_height = nwp_data.shape\n",
    "        nwp_data = nwp_data.reshape(batch_size, n_nwp_chans * nwp_width * nwp_height)\n",
    "        out = torch.cat((out, nwp_data), dim=1)\n",
    "        \n",
    "        if EMBEDDING_DIM:\n",
    "            pv_embedding = self.pv_system_id_embedding(x['pv_system_row_number'])\n",
    "            out = torch.cat(\n",
    "                (\n",
    "                    out,\n",
    "                    pv_embedding\n",
    "                    #(x['nwp_above_pv'][:, 0] - 130) / 5,  # TODO fix horrible standardisation of temperature!\n",
    "                ), dim=1)\n",
    "\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = F.relu(self.fc3(out))\n",
    "        out = F.relu(self.fc4(out))\n",
    "        out = self.fc5(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def _training_or_validation_step(self, batch, is_train_step):\n",
    "        y_hat = self(batch)\n",
    "        y = batch['pv_yield'][:, self.history_len:]\n",
    "        #y = torch.rand((32, 1), device=self.device)\n",
    "        #mse_loss = F.mse_loss(y_hat, y)\n",
    "        mae_loss = (y_hat - y).abs().mean()\n",
    "        tag = \"Train\" if is_train_step else \"Validation\"\n",
    "        #self.log_dict({'MSE/' + tag: mse_loss}, on_step=is_train_step, on_epoch=True)\n",
    "        self.log_dict({'MAE/' + tag: mae_loss}, on_step=is_train_step, on_epoch=True)\n",
    "        return mae_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._training_or_validation_step(batch, is_train_step=True)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._training_or_validation_step(batch, is_train_step=False)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eee05878-ad3e-46a9-9719-37eab1505997",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitAutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d53ba3d3-e9a9-4948-829f-b6b2a6199d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1, max_epochs=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb05006-b2df-426c-a775-e41402abf7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | sat_conv1 | Conv2d    | 720   \n",
      "1 | sat_conv2 | Conv2d    | 1.4 K \n",
      "2 | sat_conv3 | Conv2d    | 1.4 K \n",
      "3 | maxpool   | MaxPool2d | 0     \n",
      "4 | fc1       | Linear    | 4.5 M \n",
      "5 | fc2       | Linear    | 38.0 K\n",
      "6 | fc3       | Linear    | 16.5 K\n",
      "7 | fc4       | Linear    | 16.5 K\n",
      "8 | fc5       | Linear    | 129   \n",
      "----------------------------------------\n",
      "4.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.5 M     Total params\n",
      "18.142    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|                                                                  | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jack/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "DEBUG:nowcasting_dataset:Opening satellite data: gs://solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr_int16_single_timestep.zarr\n",
      "DEBUG:nowcasting_dataset:Opening NWP data: gs://solar-pv-nowcasting-data/NWP/UK_Met_Office/UKV_zarr\n",
      "/home/jack/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 0it [00:00, ?it/s]                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jack/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "DEBUG:nowcasting_dataset:Opening satellite data: gs://solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr_int16_single_timestep.zarr\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "DEBUG:nowcasting_dataset:Opening NWP data: gs://solar-pv-nowcasting-data/NWP/UK_Met_Office/UKV_zarr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 1025it [1:00:02,  3.51s/it, loss=0.234, v_num=174]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:nowcasting_dataset:Opening satellite data: gs://solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr_int16_single_timestep.zarr\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "DEBUG:nowcasting_dataset:Opening NWP data: gs://solar-pv-nowcasting-data/NWP/UK_Met_Office/UKV_zarr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: : 1026it [1:00:24,  3.53s/it, loss=0.234, v_num=174]\n",
      "Epoch 0: : 1027it [1:00:27,  3.53s/it, loss=0.234, v_num=174]\n",
      "Epoch 0: : 1028it [1:00:32,  3.53s/it, loss=0.234, v_num=174]\n",
      "Epoch 0: : 1029it [1:00:35,  3.53s/it, loss=0.234, v_num=174]\n",
      "Epoch 0: : 1030it [1:00:39,  3.53s/it, loss=0.234, v_num=174]"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c4c66f-cdc5-4319-b7c8-0b7dddf438d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model_state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d607e2-f10e-4c07-88bf-492c0215c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10119390-bdc1-4724-b5f8-1aa3877d5293",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e025240-b406-4add-9564-e27358f65d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nowcasting_dataset",
   "language": "python",
   "name": "nowcasting_dataset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
