{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ed2241-5fae-4982-b27c-7e16ac3c986b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jack/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/pytorch_lightning/metrics/__init__.py:43: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  rank_zero_deprecation(\n"
     ]
    }
   ],
   "source": [
    "from nowcasting_dataset.datamodule import NowcastingDataModule\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb0430bf-7df9-4da5-ba27-14b9e385aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15f088d0-32c2-4578-b264-07cf44e22d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = Path('solar-pv-nowcasting-data')\n",
    "\n",
    "# Solar PV data\n",
    "PV_PATH = BUCKET / 'PV/PVOutput.org'\n",
    "PV_DATA_FILENAME = PV_PATH / 'UK_PV_timeseries_batch.nc'\n",
    "PV_METADATA_FILENAME = PV_PATH / 'UK_PV_metadata.csv'\n",
    "\n",
    "SAT_FILENAME = BUCKET / 'satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr_int16_single_timestep_quarter_geospatial.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87204c81-40d5-4c5a-84c0-fe757e61b43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51 µs, sys: 8 µs, total: 59 µs\n",
      "Wall time: 62.5 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_module = NowcastingDataModule(\n",
    "    #pv_power_filename=PV_DATA_FILENAME,\n",
    "    #pv_metadata_filename=f'gs://{PV_METADATA_FILENAME}',\n",
    "    batch_size = 32,\n",
    "    history_len = 0,  #: Number of timesteps of history, not including t0.\n",
    "    forecast_len = 1,  #: Number of timesteps of forecast.\n",
    "    sat_filename = f'gs://{SAT_FILENAME}',\n",
    "    pin_memory = True,  #: Passed to DataLoader.\n",
    "    num_workers = 16,  #: Passed to DataLoader.\n",
    "    prefetch_factor = 256,  #: Passed to DataLoader.\n",
    "    n_samples_per_timestep = 2,  #: Passed to NowcastingDataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e16ce731-0d4a-4684-87b1-e07d786e12da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.53 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#data_module.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a1e5556-a223-480b-ae12-84069d3ebe19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.53 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b5a6369-0f60-4256-af54-6d449da8271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_module.train_t0_datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd09cc49-7ab5-45ba-90fc-12ea54635aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_module.val_t0_datetimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cee088-d110-4e7f-a917-2ab3acaa5eff",
   "metadata": {},
   "source": [
    "## Define very simple ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2984ce1d-1655-41b2-b6d9-5d439e26806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_images_in_model(images, device):    \n",
    "    SAT_IMAGE_MEAN = torch.tensor(93.23458, dtype=torch.float, device=device)\n",
    "    SAT_IMAGE_STD = torch.tensor(115.34247, dtype=torch.float, device=device)\n",
    "    \n",
    "    images = images.float()\n",
    "    images -= SAT_IMAGE_MEAN\n",
    "    images /= SAT_IMAGE_STD\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26cfd2b8-8d2e-4823-b558-cc7c900f1a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS = 32\n",
    "KERNEL = 3\n",
    "\n",
    "\n",
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        history_len: int=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.history_len = history_len\n",
    "        \n",
    "        self.encoder_conv1 = nn.Conv2d(in_channels=1, out_channels=CHANNELS//2, kernel_size=KERNEL)\n",
    "        self.encoder_conv2 = nn.Conv2d(in_channels=CHANNELS//2, out_channels=CHANNELS, kernel_size=KERNEL)\n",
    "        self.encoder_conv3 = nn.Conv2d(in_channels=CHANNELS, out_channels=CHANNELS, kernel_size=KERNEL)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=KERNEL)\n",
    "        \n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=CHANNELS * 11 * 11, \n",
    "            out_features=256  # Minus 2 (2 for the NWP temperature above the PV system)\n",
    "        )\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=128)\n",
    "        self.fc4 = nn.Linear(in_features=128, out_features=128)\n",
    "        self.fc5 = nn.Linear(in_features=128, out_features=1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        images = x['sat_data'][:, self.history_len:, :, :, 0]\n",
    "        images = normalise_images_in_model(images, self.device)\n",
    "        \n",
    "        # Pass data through the network :)\n",
    "        out = F.relu(self.encoder_conv1(images))\n",
    "        out = self.maxpool(out)\n",
    "        out = F.relu(self.encoder_conv2(out))\n",
    "        out = self.maxpool(out)\n",
    "        out = F.relu(self.encoder_conv3(out))\n",
    "        \n",
    "        out = out.view(-1, CHANNELS * 11 * 11)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        \n",
    "        out = torch.cat(\n",
    "            (\n",
    "                out, \n",
    "                #(x['nwp_above_pv'][:, 0] - 130) / 5,  # TODO fix horrible standardisation of temperature!\n",
    "            ), dim=1)\n",
    "\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = F.relu(self.fc3(out))\n",
    "        out = F.relu(self.fc4(out))\n",
    "        out = self.fc5(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def _training_or_validation_step(self, batch, is_train_step):\n",
    "        y_hat = self(batch)\n",
    "        #y = batch['pv_yield'][:, self.history_len:]\n",
    "        y = torch.rand((32, 1), device=self.device)\n",
    "        #mse_loss = F.mse_loss(y_hat, y)\n",
    "        mae_loss = (y_hat - y).abs().mean()\n",
    "        tag = \"Train\" if is_train_step else \"Validation\"\n",
    "        #self.log_dict({'MSE/' + tag: mse_loss}, on_step=is_train_step, on_epoch=True)\n",
    "        self.log_dict({'MAE/' + tag: mae_loss}, on_step=is_train_step, on_epoch=True)\n",
    "        return mae_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._training_or_validation_step(batch, is_train_step=True)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._training_or_validation_step(batch, is_train_step=False)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eee05878-ad3e-46a9-9719-37eab1505997",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitAutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d53ba3d3-e9a9-4948-829f-b6b2a6199d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb05006-b2df-426c-a775-e41402abf7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type      | Params\n",
      "--------------------------------------------\n",
      "0 | encoder_conv1 | Conv2d    | 160   \n",
      "1 | encoder_conv2 | Conv2d    | 4.6 K \n",
      "2 | encoder_conv3 | Conv2d    | 9.2 K \n",
      "3 | maxpool       | MaxPool2d | 0     \n",
      "4 | fc1           | Linear    | 991 K \n",
      "5 | fc2           | Linear    | 32.9 K\n",
      "6 | fc3           | Linear    | 16.5 K\n",
      "7 | fc4           | Linear    | 16.5 K\n",
      "8 | fc5           | Linear    | 129   \n",
      "--------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.286     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:  50%|█████     | 1/2 [00:06<00:06,  6.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jack/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 1837it [01:03, 28.90it/s, loss=0.254, v_num=93]            "
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nowcasting_dataset",
   "language": "python",
   "name": "nowcasting_dataset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
