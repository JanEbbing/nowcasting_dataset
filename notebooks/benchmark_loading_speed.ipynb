{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ed2241-5fae-4982-b27c-7e16ac3c986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nowcasting_dataset.datamodule import NowcastingDataModule\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from neptune.new.integrations.pytorch_lightning import NeptuneLogger\n",
    "\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger('nowcasting_dataset')\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f088d0-32c2-4578-b264-07cf44e22d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = Path('solar-pv-nowcasting-data')\n",
    "\n",
    "# Solar PV data\n",
    "PV_PATH = BUCKET / 'PV/PVOutput.org'\n",
    "PV_DATA_FILENAME = PV_PATH / 'UK_PV_timeseries_batch.nc'\n",
    "PV_METADATA_FILENAME = PV_PATH / 'UK_PV_metadata.csv'\n",
    "\n",
    "# SAT_FILENAME = BUCKET / 'satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr_int16_single_timestep_quarter_geospatial.zarr'\n",
    "SAT_FILENAME = BUCKET / 'satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr_int16_single_timestep.zarr'\n",
    "\n",
    "# Numerical weather predictions\n",
    "#NWP_BASE_PATH = BUCKET / 'NWP/UK_Met_Office/UKV_zarr'\n",
    "#NWP_BASE_PATH = BUCKET / 'NWP/UK_Met_Office/UKV_single_step_and_single_timestep_all_vars.zarr'\n",
    "#NWP_BASE_PATH = BUCKET / 'NWP/UK_Met_Office/UKV_single_step_and_single_timestep_all_vars_full_spatial_2018_7-12_float32.zarr'\n",
    "NWP_BASE_PATH = BUCKET / 'NWP/UK_Met_Office/UKV__2018-01_to_2019-12__chunks__variable10__init_time1__step1__x548__y704__.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9359c9b-1ecd-41d4-9613-a4fbe61cbfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    batch_size=32,\n",
    "    history_len=6,  #: Number of timesteps of history, not including t0.\n",
    "    forecast_len=12,  #: Number of timesteps of forecast.\n",
    "    image_size_pixels=32,\n",
    "    nwp_channels=('t', 'dswrf', 'prate', 'r', 'sde', 'si10', 'vis', 'lcc', 'mcc', 'hcc'),\n",
    "    sat_channels=(\n",
    "        'HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120',\n",
    "        'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87204c81-40d5-4c5a-84c0-fe757e61b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = NowcastingDataModule(\n",
    "    pv_power_filename=PV_DATA_FILENAME,\n",
    "    pv_metadata_filename=f'gs://{PV_METADATA_FILENAME}',\n",
    "    sat_filename = f'gs://{SAT_FILENAME}',\n",
    "    nwp_base_path = f'gs://{NWP_BASE_PATH}',\n",
    "    pin_memory = True,  #: Passed to DataLoader.\n",
    "    num_workers = 22,  #: Passed to DataLoader.\n",
    "    prefetch_factor = 256,  #: Passed to DataLoader.\n",
    "    n_samples_per_timestep = 8,  #: Passed to NowcastingDataset\n",
    "    **params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feb2f98b-aa30-4bf9-9b35-2046b1ef3847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:nowcasting_dataset:Opening satellite data: gs://solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr_int16_single_timestep.zarr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 bad PV systems found and removed!\n",
      "pv_power = 400.0 MB\n"
     ]
    }
   ],
   "source": [
    "data_module.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd2aed91-9f70-4a56-b226-41586fbc8f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:nowcasting_dataset:Opening satellite data: gs://solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr_int16_single_timestep.zarr\n",
      "DEBUG:nowcasting_dataset:Opening NWP data: gs://solar-pv-nowcasting-data/NWP/UK_Met_Office/UKV__2018-01_to_2019-12__chunks__variable10__init_time1__step1__x548__y704__.zarr\n",
      "DEBUG:nowcasting_dataset:Opening satellite data: gs://solar-pv-nowcasting-data/satellite/EUMETSAT/SEVIRI_RSS/OSGB36/all_zarr_int16_single_timestep.zarr\n",
      "/home/jack/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/pvlib/solarposition.py:368: FutureWarning: casting datetime64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
      "  unixtime = np.array(time.astype(np.int64)/10**9)\n",
      "/home/jack/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/pvlib/solarposition.py:368: FutureWarning: casting datetime64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
      "  unixtime = np.array(time.astype(np.int64)/10**9)\n",
      "/home/jack/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/pvlib/solarposition.py:368: FutureWarning: casting datetime64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
      "  unixtime = np.array(time.astype(np.int64)/10**9)\n",
      "/home/jack/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/pvlib/solarposition.py:368: FutureWarning: casting datetime64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
      "  unixtime = np.array(time.astype(np.int64)/10**9)\n",
      "/home/jack/dev/ocf/nowcasting_dataset/nowcasting_dataset/utils.py:21: FutureWarning: casting datetime64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
      "  a = a.astype(int)\n"
     ]
    }
   ],
   "source": [
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff96d7f3-9ba9-4c26-8c0b-623a13688b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2018-06-01 03:50:00', '2018-06-01 03:55:00',\n",
       "               '2018-06-01 04:00:00', '2018-06-01 04:05:00',\n",
       "               '2018-06-01 04:10:00', '2018-06-01 04:15:00',\n",
       "               '2018-06-01 04:20:00', '2018-06-01 04:25:00',\n",
       "               '2018-06-01 04:30:00', '2018-06-01 04:35:00',\n",
       "               ...\n",
       "               '2019-06-16 15:15:00', '2019-06-16 15:20:00',\n",
       "               '2019-06-16 15:25:00', '2019-06-16 15:30:00',\n",
       "               '2019-06-16 15:35:00', '2019-06-16 15:40:00',\n",
       "               '2019-06-16 15:45:00', '2019-06-16 15:50:00',\n",
       "               '2019-06-16 15:55:00', '2019-06-16 16:00:00'],\n",
       "              dtype='datetime64[ns]', length=47620, freq=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module.train_t0_datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47ddf1d7-3702-41d1-aa82-8d6ca5a5de1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-06-16 16:05:00', '2019-06-16 16:10:00',\n",
       "               '2019-06-16 16:15:00', '2019-06-16 16:20:00',\n",
       "               '2019-06-16 16:25:00', '2019-06-16 16:30:00',\n",
       "               '2019-06-16 16:35:00', '2019-06-16 16:40:00',\n",
       "               '2019-06-16 16:45:00', '2019-06-16 16:50:00',\n",
       "               ...\n",
       "               '2019-08-20 18:00:00', '2019-08-20 18:05:00',\n",
       "               '2019-08-20 18:10:00', '2019-08-20 18:15:00',\n",
       "               '2019-08-20 18:20:00', '2019-08-20 18:25:00',\n",
       "               '2019-08-20 18:30:00', '2019-08-20 18:35:00',\n",
       "               '2019-08-20 18:40:00', '2019-08-20 18:45:00'],\n",
       "              dtype='datetime64[ns]', length=11904, freq=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module.val_t0_datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6faa9de-3549-476e-8173-254ffdac928b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "940"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_module.pv_data_source.pv_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cee088-d110-4e7f-a917-2ab3acaa5eff",
   "metadata": {},
   "source": [
    "## Define very simple ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92be2a-9365-4d22-8f8c-11270b9f11d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tilemapbase\n",
    "from nowcasting_dataset.geospatial import osgb_to_lat_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ad8994-e8b2-47d9-87b1-ca57b08e3cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tilemapbase.init(create=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39a6ce6-201c-4b5a-bb25-3810f81d11aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example(batch, model_output, example_i: int=0, border: int=0):\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    ncols=4\n",
    "    nrows=2\n",
    "    \n",
    "    # Satellite data\n",
    "    extent = (\n",
    "        float(batch['sat_x_coords'][example_i, 0].cpu().numpy()), \n",
    "        float(batch['sat_x_coords'][example_i, -1].cpu().numpy()), \n",
    "        float(batch['sat_y_coords'][example_i, -1].cpu().numpy()), \n",
    "        float(batch['sat_y_coords'][example_i, 0].cpu().numpy()))  # left, right, bottom, top\n",
    "    \n",
    "    def _format_ax(ax):\n",
    "        ax.scatter(\n",
    "            batch['x_meters_center'][example_i].cpu(), \n",
    "            batch['y_meters_center'][example_i].cpu(), \n",
    "            s=500, color='white', marker='x')\n",
    "\n",
    "    ax = fig.add_subplot(nrows, ncols, 1) #, projection=ccrs.OSGB(approx=False))\n",
    "    sat_data = batch['sat_data'][example_i, :, :, :, 0].cpu().numpy()\n",
    "    sat_min = np.min(sat_data)\n",
    "    sat_max = np.max(sat_data)\n",
    "    ax.imshow(sat_data[0], extent=extent, interpolation='none', vmin=sat_min, vmax=sat_max)\n",
    "    ax.set_title('t = -{}'.format(params['history_len']))\n",
    "    _format_ax(ax)\n",
    "\n",
    "    ax = fig.add_subplot(nrows, ncols, 2)\n",
    "    ax.imshow(sat_data[params['history_len']+1], extent=extent, interpolation='none', vmin=sat_min, vmax=sat_max)\n",
    "    ax.set_title('t = 0')\n",
    "    _format_ax(ax)\n",
    "    \n",
    "    ax = fig.add_subplot(nrows, ncols, 3)\n",
    "    ax.imshow(sat_data[-1], extent=extent, interpolation='none', vmin=sat_min, vmax=sat_max)\n",
    "    ax.set_title('t = {}'.format(params['forecast_len']))\n",
    "    _format_ax(ax)\n",
    "    \n",
    "    ax = fig.add_subplot(nrows, ncols, 4)\n",
    "    lat_lon_bottom_left = osgb_to_lat_lon(extent[0], extent[2])\n",
    "    lat_lon_top_right = osgb_to_lat_lon(extent[1], extent[3])\n",
    "    tiles = tilemapbase.tiles.build_OSM()\n",
    "    lat_lon_extent = tilemapbase.Extent.from_lonlat(\n",
    "        longitude_min=lat_lon_bottom_left[1],\n",
    "        longitude_max=lat_lon_top_right[1],\n",
    "        latitude_min=lat_lon_bottom_left[0],\n",
    "        latitude_max=lat_lon_top_right[0])\n",
    "    plotter = tilemapbase.Plotter(lat_lon_extent, tile_provider=tiles, zoom=6)\n",
    "    plotter.plot(ax, tiles)\n",
    "\n",
    "    ############## TIMESERIES ##################\n",
    "    # NWP\n",
    "    ax = fig.add_subplot(nrows, ncols, 5)\n",
    "    nwp_dt_index = pd.to_datetime(batch['nwp_target_time'][example_i].cpu().numpy(), unit='s')\n",
    "    pd.DataFrame(\n",
    "        batch['nwp'][example_i, :, :, 0, 0].T.cpu().numpy(), \n",
    "        index=nwp_dt_index,\n",
    "        columns=params['nwp_channels']).plot(ax=ax)\n",
    "    ax.set_title('NWP')\n",
    "\n",
    "    # datetime features\n",
    "    ax = fig.add_subplot(nrows, ncols, 6)\n",
    "    ax.set_title('datetime features')\n",
    "    datetime_feature_cols = ['hour_of_day_sin', 'hour_of_day_cos', 'day_of_year_sin', 'day_of_year_cos']\n",
    "    datetime_features_df = pd.DataFrame(index=nwp_dt_index, columns=datetime_feature_cols)\n",
    "    for key in datetime_feature_cols:\n",
    "        datetime_features_df[key] = batch[key][example_i].cpu().numpy()\n",
    "    datetime_features_df.plot(ax=ax)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(nwp_dt_index[0].date())\n",
    "\n",
    "    # PV yield\n",
    "    ax = fig.add_subplot(nrows, ncols, 7)\n",
    "    ax.set_title('PV yield for PV ID {:,d}'.format(batch['pv_system_id'][example_i].cpu()))\n",
    "    pv_actual = pd.Series(\n",
    "        batch['pv_yield'][example_i].cpu().numpy(),\n",
    "        index=nwp_dt_index,\n",
    "        name='actual')\n",
    "    pv_pred = pd.Series(\n",
    "        model_output[example_i].detach().cpu().numpy(),\n",
    "        index=nwp_dt_index[params['history_len']+1:],\n",
    "        name='prediction')\n",
    "    pd.concat([pv_actual, pv_pred], axis='columns').plot(ax=ax)\n",
    "    ax.legend()\n",
    "\n",
    "    # fig.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d54e50f-e1de-48bb-9e3d-3c7b06927bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_example(batch, model_output, example_i=20);  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12c8cbe-6cf1-42af-b699-9215bc16ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAT_X_MEAN = np.float32(309000)\n",
    "SAT_X_STD = np.float32(316387.42073603)\n",
    "SAT_Y_MEAN = np.float32(519000)\n",
    "SAT_Y_STD = np.float32(406454.17945938)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750bb25b-add8-47c7-86aa-5ff9c6faa6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune.new.types import File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cfd2b8-8d2e-4823-b558-cc7c900f1a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_SEQ_LEN = params['history_len'] + params['forecast_len'] + 1\n",
    "CHANNELS = 32\n",
    "N_CHANNELS_LAST_CONV = 4\n",
    "KERNEL = 3\n",
    "EMBEDDING_DIM = 16\n",
    "NWP_SIZE = 10 * 2 * 2  # channels x width x height\n",
    "N_DATETIME_FEATURES = 4\n",
    "CNN_OUTPUT_SIZE = N_CHANNELS_LAST_CONV * ((params['image_size_pixels'] - 6) ** 2)\n",
    "FC_OUTPUT_SIZE = 8\n",
    "RNN_HIDDEN_SIZE = 16\n",
    "\n",
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        history_len = params['history_len'],\n",
    "        forecast_len = params['forecast_len'],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.history_len = history_len\n",
    "        self.forecast_len = forecast_len\n",
    "\n",
    "        self.sat_conv1 = nn.Conv2d(in_channels=len(params['sat_channels'])+5, out_channels=CHANNELS, kernel_size=KERNEL)#, groups=history_len+1)\n",
    "        self.sat_conv2 = nn.Conv2d(in_channels=CHANNELS, out_channels=CHANNELS, kernel_size=KERNEL) #, groups=CHANNELS//2)\n",
    "        self.sat_conv3 = nn.Conv2d(in_channels=CHANNELS, out_channels=N_CHANNELS_LAST_CONV, kernel_size=KERNEL) #, groups=CHANNELS)\n",
    "\n",
    "        #self.maxpool = nn.MaxPool2d(kernel_size=KERNEL)\n",
    "\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=CNN_OUTPUT_SIZE, \n",
    "            out_features=256)\n",
    "\n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features=256 + EMBEDDING_DIM,\n",
    "            out_features=128)\n",
    "        #self.fc2 = nn.Linear(in_features=EMBEDDING_DIM + N_DATETIME_FEATURES, out_features=128)\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.fc4 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.fc5 = nn.Linear(in_features=32, out_features=FC_OUTPUT_SIZE)\n",
    "\n",
    "        if EMBEDDING_DIM:\n",
    "            self.pv_system_id_embedding = nn.Embedding(\n",
    "                num_embeddings=len(data_module.pv_data_source.pv_metadata),\n",
    "                embedding_dim=EMBEDDING_DIM)\n",
    "            \n",
    "            \n",
    "        self.encoder_rnn = nn.GRU(\n",
    "            input_size=FC_OUTPUT_SIZE + N_DATETIME_FEATURES + 1 + NWP_SIZE,  # plus 1 for history\n",
    "            hidden_size=RNN_HIDDEN_SIZE,\n",
    "            num_layers=2,\n",
    "            batch_first=True)\n",
    "        self.decoder_rnn = nn.GRU(\n",
    "            input_size=FC_OUTPUT_SIZE + N_DATETIME_FEATURES + NWP_SIZE,\n",
    "            hidden_size=RNN_HIDDEN_SIZE,\n",
    "            num_layers=2,\n",
    "            batch_first=True)\n",
    "        \n",
    "        self.decoder_fc1 = nn.Linear(\n",
    "            in_features=RNN_HIDDEN_SIZE,\n",
    "            out_features=8)\n",
    "        self.decoder_fc2 = nn.Linear(\n",
    "            in_features=8,\n",
    "            out_features=1)\n",
    "        \n",
    "        ### EXTRA CHANNELS\n",
    "        # Center marker\n",
    "        new_batch_size = params['batch_size'] * TOTAL_SEQ_LEN\n",
    "        self.center_marker = torch.zeros(\n",
    "            (\n",
    "                new_batch_size, \n",
    "                1, \n",
    "                params['image_size_pixels'], \n",
    "                params['image_size_pixels']\n",
    "            ),\n",
    "            dtype=torch.float32, device=self.device)\n",
    "        half_width = params['image_size_pixels'] // 2\n",
    "        self.center_marker[..., half_width-2:half_width+2, half_width-2:half_width+2] = 1\n",
    "        \n",
    "        # pixel x & y\n",
    "        pixel_range = (torch.arange(params['image_size_pixels'], device=self.device) - 64) / 37\n",
    "        pixel_range = pixel_range.unsqueeze(0).unsqueeze(0)\n",
    "        self.pixel_x = pixel_range.unsqueeze(-2).expand(new_batch_size, 1, params['image_size_pixels'], -1)\n",
    "        self.pixel_y = pixel_range.unsqueeze(-1).expand(new_batch_size, 1, -1, params['image_size_pixels'])\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # ******************* Satellite imagery *************************\n",
    "        # Shape: batch_size, seq_length, width, height, channel\n",
    "        # TODO: Use optical flow, not actual sat images of the future!\n",
    "        sat_data = x['sat_data']\n",
    "        batch_size, seq_len, width, height, n_chans = sat_data.shape\n",
    "\n",
    "        # Stack timesteps as extra examples\n",
    "        new_batch_size = batch_size * seq_len\n",
    "        #                                 0           1       2      3\n",
    "        sat_data = sat_data.reshape(new_batch_size, width, height, n_chans)\n",
    "\n",
    "        # Conv2d expects channels to be the 2nd dim!\n",
    "        sat_data = sat_data.permute(0, 3, 1, 2)\n",
    "        # Now shape: new_batch_size, n_chans, width, height\n",
    "\n",
    "        ### EXTRA CHANNELS\n",
    "        # geo-spatial x\n",
    "        x_coords = x['sat_x_coords']  # shape:  batch_size, image_size_pixels\n",
    "        x_coords = x_coords - SAT_X_MEAN\n",
    "        x_coords = x_coords / SAT_X_STD\n",
    "        x_coords = x_coords.unsqueeze(1).expand(-1, width, -1).unsqueeze(1).repeat_interleave(repeats=TOTAL_SEQ_LEN, dim=0)\n",
    "        \n",
    "        # geo-spatial y\n",
    "        y_coords = x['sat_y_coords']  # shape:  batch_size, image_size_pixels\n",
    "        y_coords = y_coords - SAT_Y_MEAN\n",
    "        y_coords = y_coords / SAT_Y_STD\n",
    "        y_coords = y_coords.unsqueeze(-1).expand(-1, -1, height).unsqueeze(1).repeat_interleave(repeats=TOTAL_SEQ_LEN, dim=0)\n",
    "        \n",
    "        # Concat\n",
    "        if sat_data.device != self.center_marker.device:\n",
    "            self.center_marker = self.center_marker.to(sat_data.device)\n",
    "            self.pixel_x = self.pixel_x.to(sat_data.device)\n",
    "            self.pixel_y = self.pixel_y.to(sat_data.device)\n",
    "        \n",
    "        sat_data = torch.cat((sat_data, self.center_marker, x_coords, y_coords, self.pixel_x, self.pixel_y), dim=1)\n",
    "        \n",
    "        del x_coords, y_coords\n",
    "\n",
    "        \n",
    "        # Pass data through the network :)\n",
    "        out = F.relu(self.sat_conv1(sat_data))\n",
    "        #out = self.maxpool(out)\n",
    "        out = F.relu(self.sat_conv2(out))\n",
    "        #out = self.maxpool(out)\n",
    "        out = F.relu(self.sat_conv3(out))\n",
    "\n",
    "        out = out.reshape(new_batch_size, CNN_OUTPUT_SIZE)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        \n",
    "        # ********************** Embedding of PV system ID *********************\n",
    "        if EMBEDDING_DIM:\n",
    "            pv_embedding = self.pv_system_id_embedding(x['pv_system_row_number'].repeat_interleave(TOTAL_SEQ_LEN))\n",
    "            out = torch.cat(\n",
    "                (\n",
    "                    out,\n",
    "                    pv_embedding\n",
    "                ), \n",
    "                dim=1)\n",
    "\n",
    "        # Fully connected layers.\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = F.relu(self.fc3(out))\n",
    "        out = F.relu(self.fc4(out))\n",
    "        out = F.relu(self.fc5(out))\n",
    "\n",
    "        # ******************* PREP DATA FOR RNN *****************************************\n",
    "        out = out.reshape(batch_size, TOTAL_SEQ_LEN, FC_OUTPUT_SIZE) # TODO: Double-check this does what we expect!\n",
    "        \n",
    "        # The RNN encoder gets recent history: satellite, NWP, datetime features, and recent PV history.\n",
    "        # The RNN decoder gets what we know about the future: satellite, NWP, and datetime features.\n",
    "\n",
    "        # *********************** NWP Data **************************************\n",
    "        nwp_data = x['nwp'].float() # Shape: batch_size, channel, seq_length, width, height\n",
    "        nwp_data = nwp_data.permute(0, 2, 1, 3, 4)  # RNN expects seq_len to be dim 1.\n",
    "        batch_size, nwp_seq_len, n_nwp_chans, nwp_width, nwp_height = nwp_data.shape\n",
    "        nwp_data = nwp_data.reshape(batch_size, nwp_seq_len, n_nwp_chans * nwp_width * nwp_height)\n",
    "\n",
    "        # Concat\n",
    "        rnn_input = torch.cat(\n",
    "            (\n",
    "                out,\n",
    "                nwp_data,\n",
    "                x['hour_of_day_sin'].unsqueeze(-1),\n",
    "                x['hour_of_day_cos'].unsqueeze(-1),\n",
    "                x['day_of_year_sin'].unsqueeze(-1),\n",
    "                x['day_of_year_cos'].unsqueeze(-1),\n",
    "            ),\n",
    "            dim=2)\n",
    "        \n",
    "        pv_yield_history = x['pv_yield'][:, :self.history_len+1].unsqueeze(-1)\n",
    "        encoder_input = torch.cat(\n",
    "            (\n",
    "                rnn_input[:, :self.history_len+1],\n",
    "                pv_yield_history\n",
    "            ),\n",
    "            dim=2)\n",
    "        \n",
    "        encoder_output, encoder_hidden = self.encoder_rnn(encoder_input)\n",
    "        decoder_output, _ = self.decoder_rnn(rnn_input[:, -self.forecast_len:], encoder_hidden)\n",
    "        # decoder_output is shape batch_size, seq_len, rnn_hidden_size\n",
    "        \n",
    "        decoder_output = F.relu(self.decoder_fc1(decoder_output))\n",
    "        decoder_output = self.decoder_fc2(decoder_output)\n",
    "        \n",
    "        return decoder_output.squeeze()\n",
    "    \n",
    "    def _training_or_validation_step(self, batch, is_train_step):\n",
    "        y_hat = self(batch)\n",
    "        y = batch['pv_yield'][:, -self.forecast_len:]\n",
    "        #y = torch.rand((32, 1), device=self.device)\n",
    "        mse_loss = F.mse_loss(y_hat, y)\n",
    "        nmae_loss = (y_hat - y).abs().mean()\n",
    "        # TODO: Compute correlation coef using np.corrcoef(tensor with shape (2, num_timesteps))[0, 1]\n",
    "        # on each example, and taking the mean across the batch?\n",
    "        tag = \"Train\" if is_train_step else \"Validation\"\n",
    "        self.log_dict({f'MSE/{tag}': mse_loss}, on_step=is_train_step, on_epoch=True)\n",
    "        self.log_dict({f'NMAE/{tag}': nmae_loss}, on_step=is_train_step, on_epoch=True)\n",
    "        \n",
    "        return nmae_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._training_or_validation_step(batch, is_train_step=True)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        if batch_idx == 0:\n",
    "            # Plot example\n",
    "            model_output = self(batch)\n",
    "            fig = plot_example(batch, model_output)\n",
    "            self.logger.experiment['validation/plot'].log(File.as_image(fig))\n",
    "            \n",
    "        return self._training_or_validation_step(batch, is_train_step=False)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7badc091-995f-4857-84ba-aafae8f2baf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitAutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dff704e-69b4-435e-969c-e37b3b07a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch():\n",
    "    train_ds = data_module.train_dataset\n",
    "    train_ds.per_worker_init(0)\n",
    "    for batch in train_ds:\n",
    "        break\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3053721-1fd9-4b40-8c9d-3fa9c377cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe597e-3f75-4ad3-b6ef-8e1de0683360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_output = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2319161-ca3b-4269-a95d-fa01dd58733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0630e543-b3af-4b54-aff4-6f71211a7b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea100fe6-8bbe-4ba4-906e-39424a940e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_example(batch, model_output, example_i=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e8ba48-4181-46c1-b274-6c4be1ca8f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = NeptuneLogger(\n",
    "    project='OpenClimateFix/predict-pv-yield',\n",
    "    #params=params,\n",
    "    #experiment_name='climatology',\n",
    "    #experiment_id='PRED-1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49161cc0-b734-4e52-92e8-74e619c4b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.log_hyperparams(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198ac13d-6672-4196-8504-0d6a35fa21aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('logger.version =', logger.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ba3d3-e9a9-4948-829f-b6b2a6199d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(gpus=1, max_epochs=10_000, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb05006-b2df-426c-a775-e41402abf7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0104b18-7305-4d45-8d7e-a574e82e06c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nowcasting_dataset",
   "language": "python",
   "name": "nowcasting_dataset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
