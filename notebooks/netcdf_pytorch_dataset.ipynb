{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad3f8ea-2a59-4300-b4c6-a00d9a6f3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import gcsfs\n",
    "from typing import List\n",
    "import io\n",
    "import hashlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from nowcasting_dataset.example import Example, to_numpy\n",
    "import nowcasting_dataset.time as nd_time\n",
    "from nowcasting_dataset.dataset import worker_init_fn\n",
    "from nowcasting_dataset.geospatial import osgb_to_lat_lon\n",
    "from nowcasting_dataset.utils import get_netcdf_filename\n",
    "\n",
    "import tilemapbase\n",
    "\n",
    "from neptune.new.integrations.pytorch_lightning import NeptuneLogger\n",
    "from neptune.new.types import File\n",
    "\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger('nowcasting_dataset')\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ed3d56d-6b6c-492c-9605-aa1e5a9ff0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetCDFDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, n_batches: int, src_path: str, tmp_path: str):\n",
    "        self.n_batches = n_batches\n",
    "        self.src_path = src_path\n",
    "        self.tmp_path = tmp_path\n",
    "        \n",
    "    def per_worker_init(self, worker_id: int):\n",
    "        self.gcs = gcsfs.GCSFileSystem()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_batches\n",
    "    \n",
    "    def __getitem__(self, batch_idx: int) -> Example:\n",
    "        \"\"\" \n",
    "        Returns a whole batch at once.\n",
    "        \"\"\"\n",
    "        netcdf_filename = get_netcdf_filename(batch_idx)\n",
    "        remote_netcdf_filename = os.path.join(self.src_path, netcdf_filename)\n",
    "        local_netcdf_filename = os.path.join(self.tmp_path, netcdf_filename)\n",
    "        self.gcs.get(remote_netcdf_filename, local_netcdf_filename)\n",
    "        batch = xr.load_dataset(local_netcdf_filename)\n",
    "        os.remove(local_netcdf_filename)\n",
    "        \n",
    "        example = Example(\n",
    "            sat_datetime_index=batch.sat_time_coords,\n",
    "            nwp_target_time=batch.nwp_time_coords)\n",
    "        for key in [\n",
    "            'nwp', 'nwp_x_coords', 'nwp_y_coords', \n",
    "            'sat_data', 'sat_x_coords', 'sat_y_coords', \n",
    "            'pv_yield', 'pv_system_id', 'pv_system_row_number',\n",
    "            'hour_of_day_sin', 'hour_of_day_cos', 'day_of_year_sin', 'day_of_year_cos']:\n",
    "            example[key] = batch[key]\n",
    "        example = to_numpy(example)\n",
    "        \n",
    "        return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd7e5066-5b4a-4dc7-9d8d-98b198a84a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataset = NetCDFDataset(1334, 'gs://solar-pv-nowcasting-data/prepared_ML_training_data/v2/train/', '/home/jack/temp/train')\n",
    "#validation_dataset = NetCDFDataset(1_000, 'gs://solar-pv-nowcasting-data/prepared_ML_training_data/v2/validation/', '/home/jack/temp/validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5a5a665-84f0-4bf9-83fd-fee3bd460d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch():\n",
    "    train_dataset.per_worker_init(0)\n",
    "    batch = train_dataset[1]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8f0b28b-8796-493f-845a-fa992c0a559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    pin_memory=True,\n",
    "    num_workers=24,\n",
    "    prefetch_factor=8,\n",
    "    worker_init_fn=worker_init_fn,\n",
    "    persistent_workers=True,\n",
    "    \n",
    "    # Disable automatic batching because NowcastingDataset.__iter__\n",
    "    # returns complete batches\n",
    "    batch_size=None,\n",
    "    #batch_sampler=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2ef4a5-4d3a-4403-ab00-09f19200d775",
   "metadata": {},
   "source": [
    "## Define simple ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1813c71-f987-45fa-ba74-4240075ee087",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    batch_size=32,\n",
    "    history_len=6,  #: Number of timesteps of history, not including t0.\n",
    "    forecast_len=12,  #: Number of timesteps of forecast.\n",
    "    image_size_pixels=32,\n",
    "    nwp_channels=('t', 'dswrf', 'prate', 'r', 'sde', 'si10', 'vis', 'lcc', 'mcc', 'hcc'),\n",
    "    sat_channels=(\n",
    "        'HRV', 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120',\n",
    "        'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a64dd12d-82ee-4680-b234-5802233f127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tilemapbase.init(create=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b1b1502-c7c4-40e5-be3e-a09de9c0863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example(batch, model_output, example_i: int=0, border: int=0):\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    ncols=4\n",
    "    nrows=2\n",
    "    \n",
    "    # Satellite data\n",
    "    extent = (\n",
    "        float(batch['sat_x_coords'][example_i, 0].cpu().numpy()), \n",
    "        float(batch['sat_x_coords'][example_i, -1].cpu().numpy()), \n",
    "        float(batch['sat_y_coords'][example_i, -1].cpu().numpy()), \n",
    "        float(batch['sat_y_coords'][example_i, 0].cpu().numpy()))  # left, right, bottom, top\n",
    "    \n",
    "    def _format_ax(ax):\n",
    "        ax.scatter(\n",
    "            batch['x_meters_center'][example_i].cpu(), \n",
    "            batch['y_meters_center'][example_i].cpu(), \n",
    "            s=500, color='white', marker='x')\n",
    "\n",
    "    ax = fig.add_subplot(nrows, ncols, 1) #, projection=ccrs.OSGB(approx=False))\n",
    "    sat_data = batch['sat_data'][example_i, :, :, :, 0].cpu().numpy()\n",
    "    sat_min = np.min(sat_data)\n",
    "    sat_max = np.max(sat_data)\n",
    "    ax.imshow(sat_data[0], extent=extent, interpolation='none', vmin=sat_min, vmax=sat_max)\n",
    "    ax.set_title('t = -{}'.format(params['history_len']))\n",
    "    _format_ax(ax)\n",
    "\n",
    "    ax = fig.add_subplot(nrows, ncols, 2)\n",
    "    ax.imshow(sat_data[params['history_len']+1], extent=extent, interpolation='none', vmin=sat_min, vmax=sat_max)\n",
    "    ax.set_title('t = 0')\n",
    "    _format_ax(ax)\n",
    "    \n",
    "    ax = fig.add_subplot(nrows, ncols, 3)\n",
    "    ax.imshow(sat_data[-1], extent=extent, interpolation='none', vmin=sat_min, vmax=sat_max)\n",
    "    ax.set_title('t = {}'.format(params['forecast_len']))\n",
    "    _format_ax(ax)\n",
    "    \n",
    "    ax = fig.add_subplot(nrows, ncols, 4)\n",
    "    lat_lon_bottom_left = osgb_to_lat_lon(extent[0], extent[2])\n",
    "    lat_lon_top_right = osgb_to_lat_lon(extent[1], extent[3])\n",
    "    tiles = tilemapbase.tiles.build_OSM()\n",
    "    lat_lon_extent = tilemapbase.Extent.from_lonlat(\n",
    "        longitude_min=lat_lon_bottom_left[1],\n",
    "        longitude_max=lat_lon_top_right[1],\n",
    "        latitude_min=lat_lon_bottom_left[0],\n",
    "        latitude_max=lat_lon_top_right[0])\n",
    "    plotter = tilemapbase.Plotter(lat_lon_extent, tile_provider=tiles, zoom=6)\n",
    "    plotter.plot(ax, tiles)\n",
    "\n",
    "    ############## TIMESERIES ##################\n",
    "    # NWP\n",
    "    ax = fig.add_subplot(nrows, ncols, 5)\n",
    "    nwp_dt_index = pd.to_datetime(batch['nwp_target_time'][example_i].cpu().numpy(), unit='s')\n",
    "    pd.DataFrame(\n",
    "        batch['nwp'][example_i, :, :, 0, 0].T.cpu().numpy(), \n",
    "        index=nwp_dt_index,\n",
    "        columns=params['nwp_channels']).plot(ax=ax)\n",
    "    ax.set_title('NWP')\n",
    "\n",
    "    # datetime features\n",
    "    ax = fig.add_subplot(nrows, ncols, 6)\n",
    "    ax.set_title('datetime features')\n",
    "    datetime_feature_cols = ['hour_of_day_sin', 'hour_of_day_cos', 'day_of_year_sin', 'day_of_year_cos']\n",
    "    datetime_features_df = pd.DataFrame(index=nwp_dt_index, columns=datetime_feature_cols)\n",
    "    for key in datetime_feature_cols:\n",
    "        datetime_features_df[key] = batch[key][example_i].cpu().numpy()\n",
    "    datetime_features_df.plot(ax=ax)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(nwp_dt_index[0].date())\n",
    "\n",
    "    # PV yield\n",
    "    ax = fig.add_subplot(nrows, ncols, 7)\n",
    "    ax.set_title('PV yield for PV ID {:,d}'.format(batch['pv_system_id'][example_i].cpu()))\n",
    "    pv_actual = pd.Series(\n",
    "        batch['pv_yield'][example_i].cpu().numpy(),\n",
    "        index=nwp_dt_index,\n",
    "        name='actual')\n",
    "    pv_pred = pd.Series(\n",
    "        model_output[example_i].detach().cpu().numpy(),\n",
    "        index=nwp_dt_index[params['history_len']+1:],\n",
    "        name='prediction')\n",
    "    pd.concat([pv_actual, pv_pred], axis='columns').plot(ax=ax)\n",
    "    ax.legend()\n",
    "\n",
    "    # fig.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ca2d951-2437-4bce-83f2-5e4a793de96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAT_X_MEAN = np.float32(309000)\n",
    "SAT_X_STD = np.float32(316387.42073603)\n",
    "SAT_Y_MEAN = np.float32(519000)\n",
    "SAT_Y_STD = np.float32(406454.17945938)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb5b7739-d5da-414e-9e5f-a74cd401e227",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_SEQ_LEN = params['history_len'] + params['forecast_len'] + 1\n",
    "CHANNELS = 32\n",
    "N_CHANNELS_LAST_CONV = 4\n",
    "KERNEL = 3\n",
    "EMBEDDING_DIM = 16\n",
    "NWP_SIZE = 10 * 2 * 2  # channels x width x height\n",
    "N_DATETIME_FEATURES = 4\n",
    "CNN_OUTPUT_SIZE = N_CHANNELS_LAST_CONV * ((params['image_size_pixels'] - 6) ** 2)\n",
    "FC_OUTPUT_SIZE = 8\n",
    "RNN_HIDDEN_SIZE = 16\n",
    "\n",
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        history_len = params['history_len'],\n",
    "        forecast_len = params['forecast_len'],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.history_len = history_len\n",
    "        self.forecast_len = forecast_len\n",
    "\n",
    "        self.sat_conv1 = nn.Conv2d(in_channels=len(params['sat_channels'])+5, out_channels=CHANNELS, kernel_size=KERNEL)#, groups=history_len+1)\n",
    "        self.sat_conv2 = nn.Conv2d(in_channels=CHANNELS, out_channels=CHANNELS, kernel_size=KERNEL) #, groups=CHANNELS//2)\n",
    "        self.sat_conv3 = nn.Conv2d(in_channels=CHANNELS, out_channels=N_CHANNELS_LAST_CONV, kernel_size=KERNEL) #, groups=CHANNELS)\n",
    "\n",
    "        #self.maxpool = nn.MaxPool2d(kernel_size=KERNEL)\n",
    "\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=CNN_OUTPUT_SIZE, \n",
    "            out_features=256)\n",
    "\n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features=256 + EMBEDDING_DIM,\n",
    "            out_features=128)\n",
    "        #self.fc2 = nn.Linear(in_features=EMBEDDING_DIM + N_DATETIME_FEATURES, out_features=128)\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.fc4 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.fc5 = nn.Linear(in_features=32, out_features=FC_OUTPUT_SIZE)\n",
    "\n",
    "        if EMBEDDING_DIM:\n",
    "            self.pv_system_id_embedding = nn.Embedding(\n",
    "                num_embeddings=940,\n",
    "                embedding_dim=EMBEDDING_DIM)\n",
    "            \n",
    "            \n",
    "        self.encoder_rnn = nn.GRU(\n",
    "            input_size=FC_OUTPUT_SIZE + N_DATETIME_FEATURES + 1 + NWP_SIZE,  # plus 1 for history\n",
    "            hidden_size=RNN_HIDDEN_SIZE,\n",
    "            num_layers=2,\n",
    "            batch_first=True)\n",
    "        self.decoder_rnn = nn.GRU(\n",
    "            input_size=FC_OUTPUT_SIZE + N_DATETIME_FEATURES + NWP_SIZE,\n",
    "            hidden_size=RNN_HIDDEN_SIZE,\n",
    "            num_layers=2,\n",
    "            batch_first=True)\n",
    "        \n",
    "        self.decoder_fc1 = nn.Linear(\n",
    "            in_features=RNN_HIDDEN_SIZE,\n",
    "            out_features=8)\n",
    "        self.decoder_fc2 = nn.Linear(\n",
    "            in_features=8,\n",
    "            out_features=1)\n",
    "        \n",
    "        ### EXTRA CHANNELS\n",
    "        # Center marker\n",
    "        new_batch_size = params['batch_size'] * TOTAL_SEQ_LEN\n",
    "        self.center_marker = torch.zeros(\n",
    "            (\n",
    "                new_batch_size, \n",
    "                1, \n",
    "                params['image_size_pixels'], \n",
    "                params['image_size_pixels']\n",
    "            ),\n",
    "            dtype=torch.float32, device=self.device)\n",
    "        half_width = params['image_size_pixels'] // 2\n",
    "        self.center_marker[..., half_width-2:half_width+2, half_width-2:half_width+2] = 1\n",
    "        \n",
    "        # pixel x & y\n",
    "        pixel_range = (torch.arange(params['image_size_pixels'], device=self.device) - 64) / 37\n",
    "        pixel_range = pixel_range.unsqueeze(0).unsqueeze(0)\n",
    "        self.pixel_x = pixel_range.unsqueeze(-2).expand(new_batch_size, 1, params['image_size_pixels'], -1)\n",
    "        self.pixel_y = pixel_range.unsqueeze(-1).expand(new_batch_size, 1, -1, params['image_size_pixels'])\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # ******************* Satellite imagery *************************\n",
    "        # Shape: batch_size, seq_length, width, height, channel\n",
    "        # TODO: Use optical flow, not actual sat images of the future!\n",
    "        sat_data = x['sat_data']\n",
    "        batch_size, seq_len, width, height, n_chans = sat_data.shape\n",
    "\n",
    "        # Stack timesteps as extra examples\n",
    "        new_batch_size = batch_size * seq_len\n",
    "        #                                 0           1       2      3\n",
    "        sat_data = sat_data.reshape(new_batch_size, width, height, n_chans)\n",
    "\n",
    "        # Conv2d expects channels to be the 2nd dim!\n",
    "        sat_data = sat_data.permute(0, 3, 1, 2)\n",
    "        # Now shape: new_batch_size, n_chans, width, height\n",
    "\n",
    "        ### EXTRA CHANNELS\n",
    "        # geo-spatial x\n",
    "        x_coords = x['sat_x_coords']  # shape:  batch_size, image_size_pixels\n",
    "        x_coords = x_coords - SAT_X_MEAN\n",
    "        x_coords = x_coords / SAT_X_STD\n",
    "        x_coords = x_coords.unsqueeze(1).expand(-1, width, -1).unsqueeze(1).repeat_interleave(repeats=TOTAL_SEQ_LEN, dim=0)\n",
    "        \n",
    "        # geo-spatial y\n",
    "        y_coords = x['sat_y_coords']  # shape:  batch_size, image_size_pixels\n",
    "        y_coords = y_coords - SAT_Y_MEAN\n",
    "        y_coords = y_coords / SAT_Y_STD\n",
    "        y_coords = y_coords.unsqueeze(-1).expand(-1, -1, height).unsqueeze(1).repeat_interleave(repeats=TOTAL_SEQ_LEN, dim=0)\n",
    "        \n",
    "        # Concat\n",
    "        if sat_data.device != self.center_marker.device:\n",
    "            self.center_marker = self.center_marker.to(sat_data.device)\n",
    "            self.pixel_x = self.pixel_x.to(sat_data.device)\n",
    "            self.pixel_y = self.pixel_y.to(sat_data.device)\n",
    "        \n",
    "        sat_data = torch.cat((sat_data, self.center_marker, x_coords, y_coords, self.pixel_x, self.pixel_y), dim=1)\n",
    "        \n",
    "        del x_coords, y_coords\n",
    "\n",
    "        \n",
    "        # Pass data through the network :)\n",
    "        out = F.relu(self.sat_conv1(sat_data))\n",
    "        #out = self.maxpool(out)\n",
    "        out = F.relu(self.sat_conv2(out))\n",
    "        #out = self.maxpool(out)\n",
    "        out = F.relu(self.sat_conv3(out))\n",
    "\n",
    "        out = out.reshape(new_batch_size, CNN_OUTPUT_SIZE)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        \n",
    "        # ********************** Embedding of PV system ID *********************\n",
    "        if EMBEDDING_DIM:\n",
    "            pv_embedding = self.pv_system_id_embedding(x['pv_system_row_number'].repeat_interleave(TOTAL_SEQ_LEN))\n",
    "            out = torch.cat(\n",
    "                (\n",
    "                    out,\n",
    "                    pv_embedding\n",
    "                ), \n",
    "                dim=1)\n",
    "\n",
    "        # Fully connected layers.\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = F.relu(self.fc3(out))\n",
    "        out = F.relu(self.fc4(out))\n",
    "        out = F.relu(self.fc5(out))\n",
    "\n",
    "        # ******************* PREP DATA FOR RNN *****************************************\n",
    "        out = out.reshape(batch_size, TOTAL_SEQ_LEN, FC_OUTPUT_SIZE) # TODO: Double-check this does what we expect!\n",
    "        \n",
    "        # The RNN encoder gets recent history: satellite, NWP, datetime features, and recent PV history.\n",
    "        # The RNN decoder gets what we know about the future: satellite, NWP, and datetime features.\n",
    "\n",
    "        # *********************** NWP Data **************************************\n",
    "        nwp_data = x['nwp'].float() # Shape: batch_size, channel, seq_length, width, height\n",
    "        nwp_data = nwp_data.permute(0, 2, 1, 3, 4)  # RNN expects seq_len to be dim 1.\n",
    "        batch_size, nwp_seq_len, n_nwp_chans, nwp_width, nwp_height = nwp_data.shape\n",
    "        nwp_data = nwp_data.reshape(batch_size, nwp_seq_len, n_nwp_chans * nwp_width * nwp_height)\n",
    "\n",
    "        # Concat\n",
    "        rnn_input = torch.cat(\n",
    "            (\n",
    "                out,\n",
    "                nwp_data,\n",
    "                x['hour_of_day_sin'].unsqueeze(-1),\n",
    "                x['hour_of_day_cos'].unsqueeze(-1),\n",
    "                x['day_of_year_sin'].unsqueeze(-1),\n",
    "                x['day_of_year_cos'].unsqueeze(-1),\n",
    "            ),\n",
    "            dim=2)\n",
    "        \n",
    "        pv_yield_history = x['pv_yield'][:, :self.history_len+1].unsqueeze(-1)\n",
    "        encoder_input = torch.cat(\n",
    "            (\n",
    "                rnn_input[:, :self.history_len+1],\n",
    "                pv_yield_history\n",
    "            ),\n",
    "            dim=2)\n",
    "        \n",
    "        encoder_output, encoder_hidden = self.encoder_rnn(encoder_input)\n",
    "        decoder_output, _ = self.decoder_rnn(rnn_input[:, -self.forecast_len:], encoder_hidden)\n",
    "        # decoder_output is shape batch_size, seq_len, rnn_hidden_size\n",
    "        \n",
    "        decoder_output = F.relu(self.decoder_fc1(decoder_output))\n",
    "        decoder_output = self.decoder_fc2(decoder_output)\n",
    "        \n",
    "        return decoder_output.squeeze()\n",
    "    \n",
    "    def _training_or_validation_step(self, batch, is_train_step):\n",
    "        y_hat = self(batch)\n",
    "        y = batch['pv_yield'][:, -self.forecast_len:]\n",
    "        #y = torch.rand((32, 1), device=self.device)\n",
    "        mse_loss = F.mse_loss(y_hat, y)\n",
    "        nmae_loss = (y_hat - y).abs().mean()\n",
    "        # TODO: Compute correlation coef using np.corrcoef(tensor with shape (2, num_timesteps))[0, 1]\n",
    "        # on each example, and taking the mean across the batch?\n",
    "        tag = \"Train\" if is_train_step else \"Validation\"\n",
    "        self.log_dict({f'MSE/{tag}': mse_loss}, on_step=is_train_step, on_epoch=True)\n",
    "        self.log_dict({f'NMAE/{tag}': nmae_loss}, on_step=is_train_step, on_epoch=True)\n",
    "        \n",
    "        return nmae_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._training_or_validation_step(batch, is_train_step=True)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        if batch_idx == 0:\n",
    "            # Plot example\n",
    "            model_output = self(batch)\n",
    "            fig = plot_example(batch, model_output)\n",
    "            self.logger.experiment['validation/plot'].log(File.as_image(fig))\n",
    "            \n",
    "        return self._training_or_validation_step(batch, is_train_step=False)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "081e8fd8-d24a-4c23-be5c-b1f8503c2b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitAutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9adcca42-b802-4ab7-b5f2-7064f1dc3d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/OpenClimateFix/predict-pv-yield/e/PRED-73\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
      "logger.version = PRED-73\n"
     ]
    }
   ],
   "source": [
    "logger = NeptuneLogger(project='OpenClimateFix/predict-pv-yield')\n",
    "logger.log_hyperparams(params)\n",
    "print('logger.version =', logger.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b08896d4-49ef-48c2-a455-1133a4071ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1, max_epochs=10_000, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9671a25b-b208-4112-9301-0e2735f29f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jack/miniconda3/envs/nowcasting_dataset/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:101: UserWarning: you defined a validation_step but have no val_dataloader. Skipping val loop\n",
      "  rank_zero_warn(f'you defined a {step_name} but have no {loader_name}. Skipping {stage} loop')\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                   | Type      | Params\n",
      "------------------------------------------------------\n",
      "0  | sat_conv1              | Conv2d    | 4.9 K \n",
      "1  | sat_conv2              | Conv2d    | 9.2 K \n",
      "2  | sat_conv3              | Conv2d    | 1.2 K \n",
      "3  | fc1                    | Linear    | 692 K \n",
      "4  | fc2                    | Linear    | 34.9 K\n",
      "5  | fc3                    | Linear    | 8.3 K \n",
      "6  | fc4                    | Linear    | 2.1 K \n",
      "7  | fc5                    | Linear    | 264   \n",
      "8  | pv_system_id_embedding | Embedding | 15.0 K\n",
      "9  | encoder_rnn            | GRU       | 5.0 K \n",
      "10 | decoder_rnn            | GRU       | 5.0 K \n",
      "11 | decoder_fc1            | Linear    | 136   \n",
      "12 | decoder_fc2            | Linear    | 9     \n",
      "------------------------------------------------------\n",
      "778 K     Trainable params\n",
      "0         Non-trainable params\n",
      "778 K     Total params\n",
      "3.114     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  84%|███████████████████████████████████▏      | 1117/1334 [00:58<00:11, 19.05it/s, loss=0.0552, v_num=D-73]"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb52460-67c9-4289-bef8-374ca7569311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcf8be8-e201-44ef-b2c0-5fc3dc6b27e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nowcasting_dataset",
   "language": "python",
   "name": "nowcasting_dataset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
